{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "from functools import reduce\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "Path(\"../results\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "        print('----Started data loading process...')\n",
    "        df = pd.read_csv(dataset)\n",
    "        print('----Data loaded.')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HPI Summarization Segmentation CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_csv = '../data/mimic-III-dataset/NOTEEVENTS.csv'\n",
    "hc_csv = '../data/hpi-dataset/HOSPITAL_COURSES_FIRSTLAST.csv'\n",
    "admit_csv = '../data/mimic-III-dataset/ADMISSIONS.csv'\n",
    "pt_csv = '../data/mimic-III-dataset/PATIENTS.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes = load_data(notes_csv)\n",
    "df_hc = load_data(hc_csv)\n",
    "df_chart = load_data(admit_csv)\n",
    "df_pt = load_data(pt_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_admit_notes = ['Admission Note', 'Attending Admission Note', 'CCU - Admit Note, History and Physical', 'CCU Admission Note', 'CCU Fellow Admit Note', 'CCU Resident Admission Note', 'EP Admit H & P', 'ICU Admission Note', 'ICU Atending Progress note', 'ICU Attdg Admit', 'ICU Attdg Admit Note', 'ICU Attending Admission Note', 'ICU Attending Admission Physician Note', 'ICU Attending Admit Note', 'MICU Admission', 'MICU Attdg Admit Note', 'MICU Attending Admission Note', 'MICU Attending Admit Note', 'MICU Resident Admission Note', 'RESIDENT ADMISSION NOTE', 'Resident Admission H&P', 'Resident Admission Note', 'Resident Admission/Observation Note', 'Resident H&P', 'Resident/Attending Admission H&P', 'Trauma SICU admission note', 'critical care admit note', 'micu attending admission note', 'micu staff admission note']\n",
    "phys_admit_notes = ['Admission H&P', 'Admission Note', 'Admission Note - MICU', 'Admission Note - Surgical Critical Care', 'Admit Note', 'Attending / Resident Admission Note', 'Attending Admission Note', 'Attending Admit Note', 'CCU Admission Note', 'CCU Admit note', 'CCU Admit: Cardiology Comprehensive Physician Note', 'CCU FELLOW ADMISSION NOTE', 'CCU Fellow Admission Note', 'Cardiology Fellow Admission', 'Cardiology Fellow Admission Note', 'Cardiology Fellow Admission Note Admission', 'Cardiology Fellow Admit', 'Cardiology Fellow Admit Addendum', 'Cardiology Fellow Admit Note', 'Cardiology Fellow CCU Admission Note', 'Cardiology Fellow CCU Admission Noted', 'Cardiology Fellow CCU admission note', 'Cardiology fellow Admission Note', 'Cardiology fellow CCU Admit note', 'Cardiology fellow CCU admission note', 'Cardiology fellow CCU admit note', 'Cardiology fellow H&P', 'Critical Care Attending Admit Note', 'Critical Care admission note', 'Critical Care attending admission', 'Critical care admit note', 'Critical care attending admission note', 'Critical care attending admit', 'Critical care staff admission note', 'Critical care staff admit note', 'EP Admission Note', 'Fellow / Physician Attending Admission Note - MICU', 'Fellow Admission', 'Fellow Admission note', 'Fellow Admit', 'Fellow admission Note', 'ICU Admission Note', 'ICU Attending Admission Note', 'ICU Attending Admit Note', 'ICU Attending Note Admission Note', 'ICU Fellow Admission Note - MICU', 'ICU Fellow/Attending Admission Note - MICU', 'ICU Resident Admission Note', 'ICU resident admission note', 'MICU ADMISSION NOTE', 'MICU Admission', 'MICU Admission Note', 'MICU Fellow Admission Note', 'MICU Overnight Intensivist Fellow Admission', 'MICU Resident / Attending Admission Note', 'MICU Resident Admission Note', 'MICU Resident/Attending Admission Note', 'MICU attending admission', 'MICU attending admission note', 'MICU attending admit note', 'MICU staff admit note', 'MS4 Admission Note', 'Medical Student/Attending Admission Note - MICU', 'Overnight Intensivist (Fellow) Admit', 'Overnight Intensivist / Fellow Admission', 'Overnight Intensivist Admission', 'Overnight Intensivist Admit', 'Overnight Intensivist Fellow Admission', 'Overnight Intensivist Fellow Admission Note - MICU', 'Overnight intensivist admission', 'Physican Resident Admission Note', 'Physican Resident Admission Note - MICU attending', 'Physician Admission Note', 'Physician Admission Note - MICU', 'Physician Attending  Admission Note', 'Physician Attending - Resident Admission Note - MI', 'Physician Attending / Resident Admission Note - MI', 'Physician Attending Admission Note', 'Physician Attending Admission Note - CCU', 'Physician Attending Admission Note - Howell', 'Physician Attending Admission Note - MICU', 'Physician Attending Admission Notel', 'Physician Attending Admit Note - MICU', 'Physician Attending Resident Admission Note - MICU', 'Physician Attending/ Resident Admission Note - MIC', 'Physician Attending/Resident Admission Note - MICU', 'Physician Fellow/Attending Admission Note - MICU', 'Physician ICU  Admission Note', 'Physician ICU Admission Note', 'Physician Resident (Attending Addendum) Admission', 'Physician Resident / Attending Admission Note', 'Physician Resident / Attending Admission Note - MI', 'Physician Resident / attending Admission Note - MI', 'Physician Resident /Attending Admission Note - MIC', 'Physician Resident /attending Admission Note - MIC', 'Physician Resident Admission Note', 'Physician Resident Admission/Progress Note - CCU', 'Physician Resident Admission/Transfer Note - MICU', 'Physician Resident Attending/Admission Note - MICU', 'Physician Resident and Attending  Admission Note -', 'Physician Resident and Attending Admission Note', 'Physician Resident and Attending Admission Note -', 'Physician Resident and Attg Admission Note - MICU', 'Physician Resident and attedning Admission Note -', 'Physician Resident and attg Admission Note - MICU', 'Physician Resident and fellow Admission Note', 'Physician Resident/ attending Admission Note - MIC', 'Physician Resident/Attending Admission Note', 'Physician Resident/Attending Admission Note - MICU', 'Physician Resident/Attening Admission Note - MICU', 'Physician Resident/ICU Attending Admission Note -', 'Physician Resident/attending  Admission Note - MIC', 'Physician Resident/attending Admission Note - MICU', 'Physician Residentand Attending  Admission Note -', 'Physician Resodent Admission Note - MICU', 'Physician Surgical Admission Note', 'Physician/Attending Resident Admission Note', 'RESIDEN ADMISSION NOTE', 'RESIDENT ADMISSION NOTE', 'Resident / Attending Admission Note', 'Resident / Attending Admission Note - MICU', 'Resident / Attending Admission Notes', 'Resident / Attending Admission notes', 'Resident / Attending Admit Notes', 'Resident / Attending admission note', 'Resident Admission Note', 'Resident Admission Note - CCU', 'Resident Admission Note / Attending Addendum', 'Resident Admission Note-critical care addendum', 'Resident Admission Note/Attending Addendum', 'Resident Admission note', 'Resident Admission note - TSICU', 'Resident Admission/ Attending Admission note', 'Resident Admit Note / Attending Addendum', 'Resident admission note', 'Resident and Attending Admission Notes - MICU', 'Residnet / Attending Admission Notes', 'SICU admission note', 'SICU resident admission note', 'Sub-Intern (4th year med student) Admission Note', 'TSICU Resident Admission Note', 'admission note', 'critical care admit note', 'critical care attending admission note', 'critical care staff admission note', 'resident admission note']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gen_admit_notes) + len(phys_admit_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_admit_notes = df_notes[df_notes['DESCRIPTION'].isin(gen_admit_notes + phys_admit_notes)]\n",
    "df_admit_notes = df_admit_notes.drop_duplicates('HADM_ID') #only keep one admit note for each patient\n",
    "df_admit_notes.reset_index(drop=True, inplace=True)\n",
    "df_admit_notes = df_admit_notes.rename(columns={\"DESCRIPTION\": \"ADMIT_NOTE_DESCRIPTION\", \"TEXT\": \"ADMIT_NOTE_TEXT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save the HPI portion of the Admit Note\n",
    "df_admit_notes['ADMIT_NOTE_TEXT'] = df_admit_notes['ADMIT_NOTE_TEXT'].apply(lambda x: \" \".join(x.split()))\n",
    "df_admit_notes['HPI_TEXT'] = df_admit_notes['ADMIT_NOTE_TEXT'].apply(lambda x: ' '.join(re.findall('(?<=HPI:).*?(?=[A-Z]+\\:)', x)))\n",
    "df_admit_notes = df_admit_notes[(df_admit_notes[\"HPI_TEXT\"] != ' ') & (df_admit_notes[\"HPI_TEXT\"] != '') & (df_admit_notes[\"HPI_TEXT\"].str.len() > 100)]\n",
    "df_admit_notes.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chart_full = df_chart.merge(df_pt, on=\"SUBJECT_ID\", how=\"left\", suffixes=('', '_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_cols = ['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'CHARTDATE', 'HOSPITAL_COURSE', 'TOKENIZED_HOSPITAL_COURSE', 'HC_HPI']\n",
    "admit_cols = ['HADM_ID', 'ADMIT_NOTE_DESCRIPTION', 'ADMIT_NOTE_TEXT', 'HPI_TEXT']\n",
    "chart_cols = ['HADM_ID', 'ADMISSION_TYPE', 'ADMISSION_LOCATION', 'MARITAL_STATUS', 'ETHNICITY', 'DIAGNOSIS', 'GENDER', 'DOB', 'HOSPITAL_EXPIRE_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_hc[hc_cols], df_admit_notes[admit_cols], df_chart_full[chart_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='HADM_ID'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"DOB\"] = df_final[\"DOB\"].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"AGE\"] = df_final.apply(lambda row: relativedelta(datetime.strptime(row['CHARTDATE'], '%Y-%m-%d'), datetime.strptime(row['DOB'], '%Y-%m-%d')).years, axis=1)\n",
    "for index, row in df_final.iterrows():\n",
    "  if row['AGE'] > 89:\n",
    "    df_final.loc[index,'AGE'] = np.nan\n",
    "df_final = df_final.drop(columns=['DOB'])\n",
    "df_final = df_final.sort_values(by=['ROW_ID'])\n",
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../data/hpi-dataset/SUMMARIZATION_HPI.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP with HPI Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi_csv = '../data/hpi-dataset/SUMMARIZATION_HPI.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpi = load_data(hpi_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV for Transformer\n",
    "# ROW ID, SUBJECT_ID, HADM_ID, TEXT, SUMMARY\n",
    "\n",
    "# Get Sentence with dates in them\n",
    "rows_list = []\n",
    "for i,row in df_hpi.iterrows():\n",
    "  age = str(int(row['AGE'])) if not np.isnan(row['AGE']) else 'NONE'\n",
    "  expired = 'YES' if row['HOSPITAL_EXPIRE_FLAG'] else 'NO'\n",
    "  # compile NLP note text\n",
    "  text = \"CATEGORY: \" + row['ADMIT_NOTE_DESCRIPTION'] + \", \" \n",
    "  text += \"TYPE: \" + row['ADMISSION_TYPE'] + \", \" \n",
    "  text += \"ADMIT LOCATION: \" + row['ADMISSION_LOCATION'] + \", \"\n",
    "  text += \"AGE: \" + age + \", \"\n",
    "  text += \"GENDER: \" + row['GENDER'] + \", \"\n",
    "  text += \"MARITAL STATUS: \" + str(row['MARITAL_STATUS']) + \", \"\n",
    "  text += \"ETHNICITY: \" + row['ETHNICITY'] + \", \"\n",
    "  text += \"ADMIT DX: \" + row['DIAGNOSIS'] + \", \"\n",
    "  text += \"ADMIT TEXT: \" + row['HPI_TEXT'].strip()\n",
    "  dict1 = {'DS_ID': row['ROW_ID'],\n",
    "          'SUBJECT_ID': row['SUBJECT_ID'],\n",
    "           'HADM_ID': row['HADM_ID'],\n",
    "           'DATE': row['CHARTDATE'],\n",
    "           'DIAGNOSIS': row['DIAGNOSIS'],\n",
    "           'EXPIRED': expired,\n",
    "           'TEXT': text,\n",
    "           'SUMMARY': row['HC_HPI'],\n",
    "           }\n",
    "  rows_list.append(dict1)\n",
    "\n",
    "df_hpi_nlp = pd.DataFrame(rows_list) \n",
    "df_hpi_nlp.insert(loc=0, column='ID', value=df_hpi_nlp.index + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train, Validate, and Test set with 90/10/10 split\n",
    "train, validate, test = np.split(df_hpi_nlp.sample(frac=1, random_state=42),[int(.8*len(df_hpi_nlp)), int(.9*len(df_hpi_nlp))])\n",
    "train = train.sort_values(by='ID').reset_index(drop=True)\n",
    "validate = validate.sort_values(by='ID').reset_index(drop=True)\n",
    "test = test.sort_values(by='ID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"../data/hpi-dataset/summarization-datasets\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpi_nlp.to_csv('../data/hpi-dataset/summarization-datasets/HPI_FULL.csv', index=False)\n",
    "train.to_csv('../data/hpi-dataset/summarization-datasetsHPI_TRAIN.csv', index=False)\n",
    "validate.to_csv('../data/hpi-dataset/summarization-datasets/HPI_VALIDATE.csv', index=False)\n",
    "test.to_csv('../data/hpi-dataset/summarization-datasets/HPI_TEST.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hpi_nlp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpi_full = '../data/hpi-dataset/summarization-datasets/HPI_FULL.csv'\n",
    "df_hpi_full = load_data(hpi_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = len(df_hpi_full)\n",
    "text_count = df_hpi_full['TEXT'].str.split().str.len()\n",
    "summary_count = df_hpi_full['SUMMARY'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Docs: \", total_docs)\n",
    "print(\"Text Mean: \", text_count.mean())\n",
    "print(\"Summary Mean: \", summary_count.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (BartModel, BartTokenizer, BartForConditionalGeneration, \n",
    "BartConfig, Seq2SeqTrainer, Seq2SeqTrainingArguments)\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.models.bart.modeling_bart import shift_tokens_right\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = '../data/hpi-dataset/summarization-datasets/HPI_TRAIN.csv'\n",
    "validation_file = '../data/hpi-dataset/summarization-datasets/HPI_VALIDATE.csv'\n",
    "test_file = '../data/hpi-dataset/summarization-datasets/HPI_TEST.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"../models/HPI-BART\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN BART\n",
    "# Original Model: facebook/bart-large-cnn\n",
    "# Original Tokenizer: facebook/bart-large\n",
    "%run \"../transformers/seq2seq/run_summarization.py\" \\\n",
    "--model_name \"facebook/bart-large-cnn\" \\\n",
    "--tokenizer_name \"facebook/bart-large\" \\\n",
    "--output_dir \"../models/HPI-BART\" \\\n",
    "--overwrite_output_dir True \\\n",
    "--train_file \"../data/hpi-dataset/summarization-datasets/HPI_TRAIN.csv\" \\\n",
    "--validation_file \"../data/hpi-dataset/summarization-datasets/HPI_VALIDATE.csv\" \\\n",
    "--test_file \"../data/hpi-dataset/summarization-datasets/HPI_TEST.csv\" \\\n",
    "--text_column TEXT \\\n",
    "--summary_column SUMMARY \\\n",
    "--max_source_length 1024 \\\n",
    "--max_target_length 150 \\\n",
    "--num_train_epochs 3 \\\n",
    "--num_beams 4 \\\n",
    "--per_device_train_batch_size=3 \\\n",
    "--per_device_eval_batch_size=3 \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--do_predict \\\n",
    "--predict_with_generate True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "consistency",
   "language": "python",
   "name": "consistency"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
